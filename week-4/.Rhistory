empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Abadi Extra Light",
font=1,
scale=c(5, 0.5))
dev.off()
}
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Georgia",
font=1,
scale=c(5, 0.5))
dev.off()
}
impact_cloud2 <- create_word_cloud2("impact", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Georgia",
font=1,
scale=c(5, 0.5))
dev.off()
}
impact_cloud2 <- create_word_cloud2("impact", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Georgia",
font=1,
scale=c(8, 0.5))
dev.off()
}
impact_cloud2 <- create_word_cloud2("impact", clean_data)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Abadi Extra Light",
font=1,
scale=c(5, 0.5))
dev.off()
}
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Avenir Next LT Pro Lig",
font=1,
scale=c(5, 0.5))
dev.off()
}
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Posterama",
font=1,
scale=c(5, 0.5))
dev.off()
}
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
empathize_cloud1 <- create_word_cloud1("empathize", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Georgia",
font=1,
scale=c(5, 0.5))
dev.off()
}
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "just", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "but", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "the", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "But", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "quarantines", '\\>'), "quarantine", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Georgia",
font=1,
scale=c(8, 0.5))
dev.off()
}
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "just", '\\>'), "", clean_data$impact)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "lot", '\\>'), "", clean_data$impact)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "part", '\\>'), "", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "because", '\\>'), "", clean_data$impact)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "things", '\\>'), "", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "made", '\\>'), "", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "because", '\\>'), "", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "exposuresillness", '\\>'), "exposures", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "quarantines", '\\>'), "quarantine", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "Because", '\\>'), "", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "disease", '\\>'), "", clean_data$impact)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "diseases", '\\>'), "", clean_data$impact)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "infectious", '\\>'), "", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
### How did infectious disease impact life along the Tigris and Euphrates? #####
### How did it impact Joseph and his associates in their work environment specifically?
clean_data$impact <- gsub(paste0('\\<', "exposures", '\\>'), "exposure", clean_data$impact)
impact_cloud2 <- create_word_cloud2("impact", clean_data)
# FUNCTION: creating a word cloud (method 2)
create_word_cloud2 <- function(col, data) {
# selecting text
select_data <- data %>%
select(col)
file_name <- paste0(col, "_data.csv")
write.csv(select_data, file=file_name, row.names=FALSE)
text <- readLines(file_name)
# cleaning text, creating word freq table
docs <- Corpus(VectorSource(text))
docs <- tm_map(docs, content_transformer(removeMostPunctuation), preserve_intra_word_dashes = TRUE)
docs <- docs %>%
tm_map(removeNumbers) %>%
tm_map(stripWhitespace)
#docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
dtm <- TermDocumentMatrix(docs)
matrix <- as.matrix(dtm)
words <- sort(rowSums(matrix), decreasing=TRUE)
df <- data.frame(word = names(words), freq=words)
# making word cloud
png(paste0(col, "_wordcloud.png"), width=20,height=10, units='in', res=300)
wordcloud(words = df$word,
freq = df$freq,
min.freq=1,
max.words=200,
random.order=FALSE,
rot.per=0.35,
colors=brewer.pal(8, "Dark2"),
family="Georgia",
font=1,
scale=c(5, 0.5))
dev.off()
}
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "also", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "yet", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "the", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "The", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "also", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "much", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "like", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "likely", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "whereas", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "this", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "This", '\\>'), "", clean_data$empathize)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "well", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "Many", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
### QUESTION: How did you relate to or empathize with Joseph? What are some ####
### differences and similarities you saw between how Joseph reports living alongside
### disease and your experiences in the last year?
### Who - individuals or groups - uses the empathize and why?
clean_data$empathize <- gsub(paste0('\\<', "seems", '\\>'), "", clean_data$empathize)
empathize_cloud2 <- create_word_cloud2("empathize", clean_data)
